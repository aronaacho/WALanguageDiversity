{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **Spoken Language Diversity Across Washington Counties**\n",
    "#### *Arona Cho (aronacho@uw.edu), Arpan Kapoor (akap1204@uw.edu)*\n",
    "###### *CSE 163 - Intermediate Data Programming | Data Science Fair Project Report & Code | University of Washington | [Github Repository](https://github.com/aronaacho/WALanguageDiversity.git)*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***\n",
    "## **Summary** \n",
    "***\n",
    "\n",
    "### Research Question 1: How does language diversity in each Washington county affect their educational attainment outcomes?\n",
    "&emsp;Language diversity was not found to have as large of an effect on educational attainment across Washington counties as we thought it might have. In fact, for certain non-English language speaking groups, it can be argued that there is an inverse relationship, where counties with more language speakers see lower rates of educational attainment. It seems that the results for each language speaking group is either the previously mentioned case, or a very slight correlation between increasing language diversity and educational attainment.\n",
    "\n",
    "### Research Question 2: How do school district budgets and spending affect spoken language diversity in Washington counties?\n",
    "&emsp;From our analysis, school district budgets and spending do not seem to have a strong effect on spoken language diversity in WA counties, nor the inverse.\n",
    "\n",
    "### Research Question 3: To what extent do Washington residents continue to practice their ancestral culture through language?\n",
    "&emsp;Generally, we have found that Washington residents with a diverse ancestral background do not have a constant relationship with the amount of ancestral language that is spoken. Rather, in counties with more ancestrally diverse populations, the rate of residents that speak only English increases as well.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***\n",
    "## **Motivation**\n",
    "***\n",
    "&emsp;Spoken language diversity in our communities directly affects the extent to which various cultures can communicate and interact with each other. Identifying the underlying reasons behind why certain Washington counties have larger ranges of spoken languages can allow for the expansion of language diversity in other counties lacking in this aspect. This helps foster closer, more personal, communities. We look at two vital areas in Washington state's primary communities: the academia space and family households. Local governments can use these conclusions to increase efforts and redirect resources in order to increase spoken language diversity in their respective territories."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***\n",
    "## **Data Setting**\n",
    "***\n",
    "&emsp; For this project, we retrieved the majority of our datasets from the United States Census, focusing on data from all 39 Washington counties of the most recent year that was on record, with the majority of our data coming from 2022. We used a total of five datasets for this research project, four of which came from the US Census. The one we did not retrieve from the US Census was the dataset containing per pupil expenditure (PPE) values for all school districts in Washington, which was retrieved from the Official Washington State Open Data Portal. For this single dataset, we used the data.wa.gov website's built in aggregation tools to filter out unnecessary data points that were not relevant for our project. This was a solution to the initial issue of the dataset's size being too large, and also made it easier for us to work with the data once it had been imported. After aggregation, we were left with data for school district names and their PPEs. We used the datasets from the US Census to merge on matching school districts in order to find which counties each district is in, allowing us to find the average PPE value for each Washington county. These datasets allowed us to examine collections of county data in a more granular manner as we were able to merge them with each other in order to create plots showing trends between the shared data values.\n",
    "\n",
    "&emsp; As the majority of this data is taken from the US Census Bureau, the population which is encapsulated is all United States residents, or all Washington State residents in our case, at the time of collection. Much of the data is respondent, meaning that the data is prone to response bias. Overall, the census data is vulnerable to response biases because of the participants succumbing to social desirability which may skew the data to support more socially acceptable answers. Despite this, we believe that some solid takeaways can be formed using the resulting graphs and data plots, and could be further supported or investigated by future research and analysis in this area.\n",
    "\n",
    "The titles, links, and sources for each dataset used in this research project are listed below:\n",
    "* School Enrollment (S1401) - US Census: https://data.census.gov/table/ACSST5Y2022.S1401?q=s1401&g=050XX00US53001\n",
    "* Language Spoken at Home (S1601) - US Census: https://data.census.gov/table/ACSST5Y2022.S1601?q=s1601&g=050XX00US53001\n",
    "* Selected Social Characteristics in the United States (DP02) - US Census: https://data.census.gov/table/ACSDP5Y2022.DP02?q=Dp02&g=050XX00US53001\n",
    "* School Districts and Associated Counties - US Census: https://www.census.gov/programs-surveys/saipe/guidance-geographies/districts-counties.html\n",
    "* Per Pupil Expenditures All Years - Washington State Open Data Portal: https://data.wa.gov/education/Per-Pupil-Expenditure_AllYears/vnm3-j8pe/about_data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***\n",
    "## **Method**\n",
    "***\n",
    "1. Retrieve the four datasets listed in the Data Setting section containing values for all 39 Washington counties from the US Census website.\n",
    "2. Retrieve the dataset containing the per pupil expenditure information for all school districts in Washington from the data.wa.gov website.\n",
    "3. Use a github repository to upload all collected datasets in order to store them in an organized, shareable manner.\n",
    "4. Use VSCode, utilizing the Live Share, Github Codespaces, and Jupyter extensions in order to collaboratively work on the code and datasets for this project.\n",
    "5. Import the datasets from the repository using Github Codespaces and create dataframes for each of them.\n",
    "6. Clean each dataset, removing any unneeded data values and reformatting any irregular indexes, columns/column names, and data values.\n",
    "7. Merge datasets to have the necessary information within the same dataframe, ready to be plotted.\n",
    "8. Use Plotly to create visuals in order to identify trends between the accumulated dataframes.\n",
    "9. If a significant correlation is suspected from the initial visualizations, perform a regression analysis to verify or disprove the suspected hypothesis.\n",
    "10. Document trends/correlations found from Plotly visualizations and any other conclusions found.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***\n",
    "## **Results and Code**\n",
    "***\n",
    "\n",
    "## Importing and Cleaning\n",
    "&emsp; Before delving into the code that produced the results for this research project, we must highlight the code used to set up and clean our datasets. This was an important part of being able to utilize and comprehend the data we found and took up a significant portion of the time spent coding for this project.\n",
    "\n",
    "**The following packages were imported:**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import plotly.express as px\n",
    "import plotly.graph_objects as go\n",
    "import statsmodels.api as sm\n",
    "from plotly.subplots import make_subplots\n",
    "import doctest\n",
    "# !pip install Pyarrow"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**The following cleaning and reformatting functions were used:**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TestResults(failed=0, attempted=6)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def clean(series):\n",
    "    '''\n",
    "    A function to clean columns in a dataframe to all lowercase strings.\n",
    "    Returns a cleaned list of the given column.\n",
    "\n",
    "    >>> clean(pd.Series([\"UPPERCASE\", \"low\", \"UPandLow\"]))\n",
    "    ['uppercase', 'low', 'upandlow']\n",
    "    >>> clean(small_test[\"Label (Grouping)\"].head(2))\n",
    "    ['population 5 years and over', '\\xa0\\xa0\\xa0\\xa0speak only english']\n",
    "    '''\n",
    "    cleaned = []\n",
    "    for row in series:\n",
    "        cleaned.append(str(row).lower())\n",
    "    return cleaned\n",
    "\n",
    "def clean_df(df):\n",
    "    '''\n",
    "    A function to clean column_name in a dataframe to all lowercase strings,\n",
    "    cleans whitespace, and replaces within-name whitespace with underscores.\n",
    "    Returns a dataframe.\n",
    "\n",
    "    >>> clean_df(reformat_census_df(small_test, 3)).columns.tolist()[1:4]\n",
    "    ['speak_only_english', 'speak_a_language_other_than_english', 'speak_a_language_other_than_english']\n",
    "    >>> clean_df(small_test).columns.tolist()[2]\n",
    "    'washington!!percent!!estimate'\n",
    "    '''\n",
    "    df = df.copy(deep=True)\n",
    "    df.columns = [name.strip().lower().replace(' ','_') for name in df.columns]\n",
    "    return df\n",
    "\n",
    "def reformat_census_df(df, num_levels):\n",
    "    '''\n",
    "    Returns a reformatted US census dataframe, with multi-indexes.\n",
    "    This function only takes in US census csv data, and must meet these requirements.\n",
    "    - The faux-index is named \"Label (Grouping)\" or \"label_(grouping)\"\n",
    "    - Faux-index includes one string of a multi-index, with '!!' as the delimiter\n",
    "    - Has a County and Ratio equivalent within the multi-index levels\n",
    "        - Ratio label type example: Estimate, percent\n",
    "\n",
    "    >>> reformat_census_df(clean_df(small_test), 3).index[1]\n",
    "    ('washington', 'percent')\n",
    "    >>> reformat_census_df(small_test, 3).index.get_level_values(1).tolist()\n",
    "    ['Total', 'Percent']\n",
    "    '''\n",
    "    df = df.copy(deep=True)\n",
    "    if \"label_(grouping)\" in df.columns:\n",
    "        df.set_index(\"label_(grouping)\", inplace=True)\n",
    "    else:\n",
    "        df.set_index(\"Label (Grouping)\", inplace=True)\n",
    "    df = df.transpose()\n",
    "    df['temp_index'] = df.index\n",
    "    regex_pattern = r\"^[\\w,\\s]+\"\n",
    "    for i in range(num_levels - 1):\n",
    "        regex_pattern += \"\\!\\![\\w,\\s]+\"\n",
    "    regex_pattern += \"$\"\n",
    "    df = df.loc[df['temp_index'].str.contains(regex_pattern)]\n",
    "    df.insert(0, \"County\", \"\")\n",
    "    df.insert(1, \"Ratio\", \"\")\n",
    "\n",
    "    for row in df['temp_index']:\n",
    "        terms = row.split(\"!!\")\n",
    "        terms[0] = terms[0].split(\",\")[0]\n",
    "        df.loc[row, ['County']] = terms[0]\n",
    "        df.loc[row, ['Ratio']] = terms[1]\n",
    "\n",
    "    df.rename_axis(None, axis=1, inplace=True)\n",
    "    df.set_index(['County', 'Ratio'], inplace=True)\n",
    "    df.drop(columns=['temp_index'], inplace=True, axis=1)\n",
    "    return df\n",
    "\n",
    "doctest.testmod()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**The following code was used to import and set up the dataframes:**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# RQ1: reading in csv containing languages spoken at home\n",
    "language_demographic = pd.read_csv(\"data/S1601LanguagesSpokenAtHome.csv\")\n",
    "language_demographic = reformat_census_df(language_demographic, 3)\n",
    "language_demographic = clean_df(language_demographic)\n",
    "language_demographic = language_demographic.loc[\n",
    "    (language_demographic.index.get_level_values(\"County\"), \"Percent\"), :]\n",
    "\n",
    "# RQ1: reading in csv containing school enrollment data\n",
    "enrollment = pd.read_csv(\"data/S1401SchoolEnrollment.csv\")\n",
    "enrollment = reformat_census_df(enrollment, 3)\n",
    "enrollment = clean_df(enrollment)\n",
    "enrollment = enrollment.loc[(enrollment.index.get_level_values(\"County\"), \"Percent\"), :]\n",
    "\n",
    "# RQ1: cleaning the languages and enrollment percentages to decimal floats\n",
    "sub_language = language_demographic.iloc[:, [1, 2, 4, 8, 12, 16]].apply(\n",
    "    lambda x: x.str.replace(\"%\",\"\").astype(float) / 100)\n",
    "\n",
    "sub_enrollment = enrollment.iloc[:, [7, 8]].apply(\n",
    "    lambda x: x.str.replace(\"%\",\"\").astype(float) / 100)\n",
    "\n",
    "# RQ2: reading in csv containing school districts and their PPE\n",
    "ppe = pd.read_csv(\"data/SchoolDistrictPPEAverages.csv\")\n",
    "ppe = clean_df(ppe)\n",
    "ppe[\"districtname\"] = clean(ppe[\"districtname\"])\n",
    "\n",
    "# RQ2: reading in csv containing counties and their school districts\n",
    "counties = pd.read_csv(\"data/Counties.csv\", header=2)\n",
    "counties = counties.loc[counties[\"State Postal Code\"] == \"WA\"]\n",
    "counties = clean_df(counties)\n",
    "counties[\"school_district_name\"] = clean(counties[\"school_district_name\"])\n",
    "\n",
    "# RQ2: merging ppe and counties by district name\n",
    "counties_ppe = ppe.merge(counties, right_on=\"school_district_name\", left_on=\"districtname\")\n",
    "counties_ppe.set_index(\"school_district_name\", inplace=True)\n",
    "counties_ppe.drop(columns=[\"districtname\"], inplace=True)\n",
    "\n",
    "# RQ2: merging ppe and languages spoken by county\n",
    "ppe_languages = counties_ppe[[\"ppe\", \"county_names\"]].groupby(\"county_names\").mean()\n",
    "ppe_languages[\"County\"] = ppe_languages.index\n",
    "ppe_languages = ppe_languages.merge(sub_language, left_on=\"county_names\", right_on=\"County\")\n",
    "ppe_languages.set_index(\"County\", inplace=True)\n",
    "\n",
    "# RQ3: reading in csv containing ancestry languages spoken at home\n",
    "households = pd.read_csv(\"data/DP02AncestryLanguagesSpokenAtHome.csv\")\n",
    "households = reformat_census_df(households, 2)\n",
    "households = clean_df(households)\n",
    "\n",
    "# RQ3: getting the total diversity for non-American ancestry\n",
    "ancestry_backgrounds = households.iloc[:, -32:-4].copy().loc[\n",
    "    (households.index.get_level_values(\"County\"), \"Estimate\"), :]\n",
    "ancestry_backgrounds = ancestry_backgrounds.apply(\n",
    "    lambda x: x.str.replace(\",\",\"\").astype(float))\n",
    "\n",
    "ancestry_backgrounds.columns = [name.strip() for name in ancestry_backgrounds.columns]\n",
    "\n",
    "# RQ3: getting the ancestry backgrounds in each county\n",
    "diverse_count = []\n",
    "full_count = [x.sum() for _, x in ancestry_backgrounds.iterrows()]\n",
    "for _, row in ancestry_backgrounds.iloc[:, 1:].iterrows():\n",
    "    diverse_count.append(row.sum())\n",
    "\n",
    "ancestry_backgrounds[\"diversity_ratio\"] = [x / y for x, y in zip(diverse_count, full_count)]\n",
    "\n",
    "# RQ3: getting the languages being used in each household and merging with ancestral backgrounds\n",
    "lang_usages = households.iloc[:, -45:-33].copy().loc[\n",
    "    (households.index.get_level_values(\"County\"), \"Percent\"), :]\n",
    "\n",
    "ancestry_backgrounds.index = ancestry_backgrounds.index.droplevel(1)\n",
    "lang_usages.index = lang_usages.index.droplevel(1)\n",
    "\n",
    "diverse_lang = pd.DataFrame(ancestry_backgrounds[\"diversity_ratio\"]).merge(\n",
    "    lang_usages, right_index=True, left_index=True)\n",
    "\n",
    "diverse_lang.iloc[:, 2:] = diverse_lang.iloc[:, 2:].apply(\n",
    "    lambda x: x.str.replace(\"%\",\"\").astype(float) / 100)\n",
    "\n",
    "diverse_lang = diverse_lang.iloc[1:, :]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**As seen in the previous code cell, the following lambda function was used in order to convert string percentage values (in the form of __._%) found in our datasets into float versions:**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lambda x: x.str.replace(\"%\",\"\").astype(float) / 100"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## RQ1: How does language diversity in each Washington county affect their educational attainment outcomes?\n",
    "&emsp; For this research question, we merged the educational enrollment and languages spoken at home datasets. This allowed us to plot the attainment values for college undergraduate and postgraduate students in all Washington counties in comparison to the rates of various different language speaking groups."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "enrollment_language = pd.merge(sub_enrollment, sub_language, on=[\"County\"])\n",
    "enrollment_language = enrollment_language.sort_values(by=\"college,_undergraduate\")\n",
    "\n",
    "all_lang_colors = [\"#AB63FA\", \"#FFA15A\", \"#FF97FF\", \"#EF553B\", \"lime\", \"magenta\"]\n",
    "\n",
    "fig1 = make_subplots(3,2, subplot_titles=(\"Spanish Speakers\",  \n",
    "                                          \"Other Indo-European Language Speakers\", \n",
    "                                          \"Asian & Pacific Island Language Speakers\", \n",
    "                                          \"Other Language Speakers\", \n",
    "                                          \"Speak Only English\", \"Speak a Language Other Than English\"))\n",
    "\n",
    "names = {\"spanish\": \"Spanish\", \n",
    "         \"other_indo-european_languages\": \"Other Indo-European Languages\", \n",
    "         \"asian_and_pacific_island_languages\": \"Asian & Pacific Island Languages\", \n",
    "         \"other_languages\": \"Other Languages\", \"speak_only_english\": \"Speak Only English\", \n",
    "         \"speak_a_language_other_than_english\": \"Speak a Language Other Than English\"}\n",
    "\n",
    "for (i, j), type, color, bool in zip([(1, 1), (1, 2), (2, 1), (2, 2), (3, 1), (3, 2)], \n",
    "                                     [\"spanish\", \"other_indo-european_languages\", \n",
    "                                      \"asian_and_pacific_island_languages\", \n",
    "                                      \"other_languages\", \"speak_only_english\", \n",
    "                                      \"speak_a_language_other_than_english\"], \n",
    "                                     all_lang_colors,\n",
    "                                     [True, False, False, False, False, False]):\n",
    "       fig1.add_trace(go.Bar(x=enrollment_language.index, \n",
    "                             y=enrollment_language[\"college,_undergraduate\"], \n",
    "                             name=\"Undergraduate\",\n",
    "                             showlegend=bool,\n",
    "                             marker_color = \"green\",\n",
    "                             opacity=0.4,\n",
    "                             marker_line_color=\"rgb(8,48,107)\",\n",
    "                             marker_line_width=2), \n",
    "                             row = i, col = j)\n",
    "       fig1.add_trace(go.Bar(x=enrollment_language.index, \n",
    "                             y=enrollment_language[\"graduate,_professional_school\"],\n",
    "                             name=\"Postgraduate Enrollment\", \n",
    "                             showlegend=bool,                  \n",
    "                             marker_color = \"blue\",                     \n",
    "                             opacity=0.4,\n",
    "                             marker_line_color=\"rgb(8,48,107)\",\n",
    "                             marker_line_width=2),\n",
    "                             row = i, col = j)\n",
    "       fig1.add_trace(go.Scatter(x=enrollment_language.index, y=enrollment_language[type], \n",
    "                                line=dict(color=color), name=names[type]), row = i, col = j)\n",
    "       \n",
    "fig1.update_layout(autosize=False, width=3000, \n",
    "                   height=1500, \n",
    "                   title_text=\"Undergraduate & Postgraduate Enrollment Percentage Compared to Percentage of\"\n",
    "                            + \" Language Speakers in Each County Ranked by Undergraduate Enrollment\",\n",
    "                  title_x=0.45, xaxis_title=\"Counties\", yaxis_title=\"Percentage\")\n",
    "\n",
    "for i in range(1, 7):\n",
    "       fig1[\"layout\"][f\"xaxis{i}\"][\"title\"]=\"Counties\"\n",
    "       fig1[\"layout\"][f\"yaxis{i}\"][\"title\"]=\"Percentage\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "&emsp; These six graphs are the ouput of the code above. Each of the six graphs has plotted bars in the background representing the enrollment percentage values of undergraduate students in green and postgraduate students in blue for each county. Additionaly for each graph, the percentage of residents who speak the highlighted language or language group is represented by the colored line plot, with one language group per graph. Each graph is sorted by undergraduate enrollment percentages by county, meaning the county with the highest undergraduate enrollment rate is on the right. Let's look at the top four graphs first, looking at speaking rates of each of the four non-English only groups. Starting with Spanish speakers, we can clearly see that there is no correlation between Spanish speakers and college enrollment in Washington counties, as there are 3-4 large spikes in speaking rates towards the lower end of the college enrollment percentages. This is the only graph out of the first four that has such a strong negative correlation. From this, a conclusion could be made opposite to what we initially hypothesized; that larger Spanish speaking and hispanic communities actually have lower college enrollment rates than English only speakers due to these communities historically recieving less economic and societal support. Although, it could be argued that this negative correlation is not relevant as there may be external factors that affect college enrollment rates within communities containing Spanish speakers. This graph was the one that suprised us the most, and also became the most thought provoking out of the ones created for the first research question.\n",
    "\n",
    "&emsp; Looking at the remaining three graphs, there is a very slight correlation between increasing language speaking rates and college enrollment rates, with the largest being seen in the Asian & Pacific Island Language Speakers graph and the smallest being seen in the Other Language Speakers graph. Although the correlation is minimal, it does help indicate that speaking a language other than English may help contribute towards higher college enrollment rates in Washington counties. However, it is most likely a minimal one of many factors that contribute towards this.\n",
    "\n",
    "&emsp; Finally, let's examine the bottom two graphs that contain information on those who speak only English, and those who speak a language other than English (a combination of the top four graphs). The majority of conclusions between these two graphs can be shared as they are essentially inverses of each other. One key detail noticed about these graphs is that there is a much higher amplitude in the speaking rates towards the lower end of college enrollment for counties, showing that counties with higher rates of English only speakers tend to have higher enrollment rates as well. Initially, this was suprising, but as we thought about it more, it became a little clearer. We can conclude that  communities with higher rates of English only speakers tend to not house as many minority populations as those with higher language diversity, thus not representing many minority communities. These minority communities are often not supported as well as their white counterparts in society, having harder times pursuing higher education after high school due to many reasons such as financial situations, housing, societal restrictions. Although these graphs did not help show that investing in increased language diversity would lead to higher college enrollment rates, it did help further illuminate the issue of struggling minority communities in relation to higher education. As well as their presence in Washingtonian and American society as communities who consistently face increased hardships in comparison to other communities who have historically held more socioeconomic strength."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"https://raw.githubusercontent.com/aronaacho/WALanguageDiversity/main/pngs/educational_outcomes.png\"/>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## RQ2: How do school district budgets and spending affect spoken language diversity in WA counties?\n",
    "&emsp; For this question, we used the merged dataset with per pupil expenditures and languages spoken at home to get a dataframe that included both variables by county. Using that dataframe, we were able to plot two subplots, with one showing the rates of the language type being spoken per county excluding English and the other showing the per pupil expenditure. These two plots use the same x-axis of counties sorted in order of the most to least per pupil expediture."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ppe_languages = ppe_languages.sort_values(by=\"ppe\", ascending=False)\n",
    "all_lang_colors = [\"#636EFA\", \"#EF553B\", \"#00CC96\", \"#AB63FA\", \"#FFA15A\"]\n",
    "all_counties = []\n",
    "\n",
    "for i in range(len(ppe_languages.index)):\n",
    "    all_counties.append(str(i + 1) + \". \" + ppe_languages.index[i])\n",
    "all_lang_types = ppe_languages.iloc[:, 2:].columns\n",
    "all_lang_labels = [\"Spanish\", \"Other Indo-European Languages\", \n",
    "                   \"Asian and Pacific Island Languages\", \"Other Languages\"]\n",
    "fig2 = make_subplots(2, 1, subplot_titles=(\n",
    "    \"Non-English Languages Spoken in WA Counties Ranked by School District Per Pupil Expenditure (PPE)\",  \n",
    "    \"WA Counties Ranked by School District Per Pupil Expenditure (PPE)\"))\n",
    "\n",
    "for i in range(len(all_lang_labels)):\n",
    "    fig2.add_trace(go.Bar(x=all_counties,\n",
    "                    y=ppe_languages[all_lang_types[i]],\n",
    "                    name=all_lang_labels[i],\n",
    "                    marker_color=all_lang_colors[i]\n",
    "                    ), row = 1, col = 1)\n",
    "    \n",
    "fig2.add_trace(go.Bar(x=all_counties,\n",
    "                y=ppe_languages[\"ppe\"],\n",
    "                name=\"PPE\",\n",
    "                marker_color=all_lang_colors[4]\n",
    "                ), row = 2, col = 1)\n",
    "\n",
    "fig2.update_layout(autosize=False, width=1300, height=1400)\n",
    "fig2[\"layout\"][\"xaxis\"][\"title\"]=\"WA Counties\"\n",
    "fig2[\"layout\"][\"xaxis2\"][\"title\"]=\"WA Counties\"\n",
    "fig2[\"layout\"][\"yaxis\"][\"title\"]=\"Percentage of Language Type Spoken\"\n",
    "fig2[\"layout\"][\"yaxis2\"][\"title\"]=\"Per Pupil Expenditure\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "&emsp; From this code above, we were able to generate this visualization below. To restate our motive for choosing to use two subplots was to search for any correlations between the amount of PPEs and the language spoken in a county. The PPE for each county was determined by taking the mean PPE of all K-12 school districts in the county. The subplots share the same x-axis of a PPE-ranked list of Washington state counties. To express the various language categories spoken in each county, we separated them by the non-English categories that were reported from our initial dataset: Spanish, Other Indo-European, Asian and Pacific Island, and Other languages. All of this resulted in the first visualization. When we order the counties by PPE, no clear trendline is shown from the tops of the bars. We chose to include the second subplot of the general average PPE by county for transparency and to also examine the slope in the directionality of the PPE averages.\n",
    "\n",
    "&emsp; We can see that from the highest PPE in Cowlitz County with around \\\\$12,000 to the lower PPE in Ferry County with around \\\\$6,500, showing is a gradual linear decrease in PPE. Comparatively, the plot above with the languages includes various spikes of Spanish and Other Indo-European languages. Overall there is basic no correlation between these two variables. This poses the question: should language diversity be a factor in PPE levels? From our results, it certainly seems as though they do not have any influence over the expenditure levels. However, because we can infer that language diversity implies racial diversity to an extent, and drawing from knowledge about the intentional survey of people of Hispanic or Latino Origin for civil rights purposes in censuses, it does not seem far fetched for language diversity to be a factor in expenditure amounts. As fluency in one language does not guarantee fluency in another, and while we also would like to look at a larger sample and English literacy rates by language, we believe that perhaps investing PPE by language diversity could benefit early to adolescent literacy in students in a direction towards higher equity in learning resources."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"https://raw.githubusercontent.com/aronaacho/WALanguageDiversity/main/pngs/ppe_by_district.png\"/>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## RQ3: To what extent do Washington residents continue to practice their ancestral culture through language?\n",
    "&emsp; Using the dataframe created above that included ancestral background and language diversity, we first plotted the language diversity by county to visualize the overall breakdown of language by county. The following plot was created by plotting the percentages of households that speak English only by a various range of language diversity that can be seen in a Washington county with a linear regression line overlaying it. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lang_counties = []\n",
    "lang_counts = []\n",
    "lang_kind = []\n",
    "\n",
    "for idx, row in diverse_lang.iterrows():\n",
    "    lang_counties.append(idx)\n",
    "    lang_counts.append(row[\"english_only\"])\n",
    "    lang_kind.append(\"English Only\")\n",
    "    lang_counties.append(idx)\n",
    "    lang_counts.append(row[\"language_other_than_english\"])\n",
    "    lang_kind.append(\"Language other than English\")\n",
    "\n",
    "lang_data = {}\n",
    "lang_data[\"County\"] = lang_counties\n",
    "lang_data[\"Percent\"] = lang_counts\n",
    "lang_data[\"Language\"] = lang_kind\n",
    "lang_data = pd.DataFrame(lang_data).sort_values(by=\"Percent\")\n",
    "fig3 = px.bar(lang_data, x=\"Percent\", y=\"County\", color=\"Language\", \n",
    "              title=\"Diversity in Language in WA Counties\", height=900)\n",
    "\n",
    "# Let's analyze the strength of the relationships of the two variables: \n",
    "# ancestral diversity in each county and English only being spoken in households\n",
    "fig3 = px.scatter(diverse_lang, y='diversity_ratio', x='english_only', trendline='ols', \n",
    "                    title='English only being spoken in Various Ancestrally Diverse WA County Households',\n",
    "                    labels=dict(diversity_ratio=\"Ancestral Diversity\", \n",
    "                                english_only=\"Households that Speak Only English\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "&emsp; First, to gauge the diversity of languages at a smaller scale, we chose to group all non-English speaking households together against the exclusively English speaking households. We were intrigued by the variability of the households that spoke English only and thought that the English Only households provided a range that was wide enough that could potentially show us a relationship to the ancestral background when utilized as a predicted variable. \n",
    "\n",
    "&emsp; The scatterplot shows the rates of English Only speaking households, as determined above, and ancestral diversity. We can clearly see a postiive and fairly strong linear relationship, indicating that there is some correlation between these two variables. Using the least-ordinary squares table, it shows that the R-squared value is 0.827, meaning that 82.7% of the variability in the ancestral diversity can be attributed to English Only households. Also, with the p-value being less than the 5% significance level of 0.000, we can reject the notion that English Only households do not have a correlation with ancestral diversity. Before running these analyses, we expected the results to have an inverse relationship, as we assumed that more ancestral diversity was indicative of more non-English languages being used. We were surprised to have found that this was the opposite and to conclude that it is to a low extent that Washington residents continue to practice their ancestral culture through language. When taking on a communicative lens to further understand these results, many times, immigrant families purposefully choose not to teach their children their native tongue in hopes of faster assimilation by picking up English and becoming Americanized. Another reason for this positive correlation could be that when counties facilitate people with diverse ancestral backgrounds, to communicate with one another, English may have defaulted to be the most universal and accessible language."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"https://raw.githubusercontent.com/aronaacho/WALanguageDiversity/main/pngs/language_diversity_per_county.png\"/>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"https://raw.githubusercontent.com/aronaacho/WALanguageDiversity/main/pngs/household_diversity.png\"/>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table class=\"simpletable\">\n",
       "<caption>OLS Regression Results</caption>\n",
       "<tr>\n",
       "  <th>Dep. Variable:</th>     <td>diversity_ratio</td> <th>  R-squared:         </th> <td>   0.827</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Model:</th>                   <td>OLS</td>       <th>  Adj. R-squared:    </th> <td>   0.822</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Method:</th>             <td>Least Squares</td>  <th>  F-statistic:       </th> <td>   177.1</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Date:</th>             <td>Tue, 12 Mar 2024</td> <th>  Prob (F-statistic):</th> <td>1.12e-15</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Time:</th>                 <td>22:47:11</td>     <th>  Log-Likelihood:    </th> <td>  94.625</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>No. Observations:</th>      <td>    39</td>      <th>  AIC:               </th> <td>  -185.3</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Df Residuals:</th>          <td>    37</td>      <th>  BIC:               </th> <td>  -181.9</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Df Model:</th>              <td>     1</td>      <th>                     </th>     <td> </td>   \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Covariance Type:</th>      <td>nonrobust</td>    <th>                     </th>     <td> </td>   \n",
       "</tr>\n",
       "</table>\n",
       "<table class=\"simpletable\">\n",
       "<tr>\n",
       "        <td></td>          <th>coef</th>     <th>std err</th>      <th>t</th>      <th>P>|t|</th>  <th>[0.025</th>    <th>0.975]</th>  \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>const</th>        <td>    0.0909</td> <td>    0.024</td> <td>    3.736</td> <td> 0.001</td> <td>    0.042</td> <td>    0.140</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>english_only</th> <td>    0.3754</td> <td>    0.028</td> <td>   13.307</td> <td> 0.000</td> <td>    0.318</td> <td>    0.433</td>\n",
       "</tr>\n",
       "</table>\n",
       "<table class=\"simpletable\">\n",
       "<tr>\n",
       "  <th>Omnibus:</th>       <td> 1.297</td> <th>  Durbin-Watson:     </th> <td>   1.591</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Prob(Omnibus):</th> <td> 0.523</td> <th>  Jarque-Bera (JB):  </th> <td>   1.044</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Skew:</th>          <td>-0.155</td> <th>  Prob(JB):          </th> <td>   0.593</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Kurtosis:</th>      <td> 2.261</td> <th>  Cond. No.          </th> <td>    13.9</td>\n",
       "</tr>\n",
       "</table><br/><br/>Notes:<br/>[1] Standard Errors assume that the covariance matrix of the errors is correctly specified."
      ],
      "text/latex": [
       "\\begin{center}\n",
       "\\begin{tabular}{lclc}\n",
       "\\toprule\n",
       "\\textbf{Dep. Variable:}    & diversity\\_ratio & \\textbf{  R-squared:         } &     0.827   \\\\\n",
       "\\textbf{Model:}            &       OLS        & \\textbf{  Adj. R-squared:    } &     0.822   \\\\\n",
       "\\textbf{Method:}           &  Least Squares   & \\textbf{  F-statistic:       } &     177.1   \\\\\n",
       "\\textbf{Date:}             & Tue, 12 Mar 2024 & \\textbf{  Prob (F-statistic):} &  1.12e-15   \\\\\n",
       "\\textbf{Time:}             &     22:47:11     & \\textbf{  Log-Likelihood:    } &    94.625   \\\\\n",
       "\\textbf{No. Observations:} &          39      & \\textbf{  AIC:               } &    -185.3   \\\\\n",
       "\\textbf{Df Residuals:}     &          37      & \\textbf{  BIC:               } &    -181.9   \\\\\n",
       "\\textbf{Df Model:}         &           1      & \\textbf{                     } &             \\\\\n",
       "\\textbf{Covariance Type:}  &    nonrobust     & \\textbf{                     } &             \\\\\n",
       "\\bottomrule\n",
       "\\end{tabular}\n",
       "\\begin{tabular}{lcccccc}\n",
       "                       & \\textbf{coef} & \\textbf{std err} & \\textbf{t} & \\textbf{P$> |$t$|$} & \\textbf{[0.025} & \\textbf{0.975]}  \\\\\n",
       "\\midrule\n",
       "\\textbf{const}         &       0.0909  &        0.024     &     3.736  &         0.001        &        0.042    &        0.140     \\\\\n",
       "\\textbf{english\\_only} &       0.3754  &        0.028     &    13.307  &         0.000        &        0.318    &        0.433     \\\\\n",
       "\\bottomrule\n",
       "\\end{tabular}\n",
       "\\begin{tabular}{lclc}\n",
       "\\textbf{Omnibus:}       &  1.297 & \\textbf{  Durbin-Watson:     } &    1.591  \\\\\n",
       "\\textbf{Prob(Omnibus):} &  0.523 & \\textbf{  Jarque-Bera (JB):  } &    1.044  \\\\\n",
       "\\textbf{Skew:}          & -0.155 & \\textbf{  Prob(JB):          } &    0.593  \\\\\n",
       "\\textbf{Kurtosis:}      &  2.261 & \\textbf{  Cond. No.          } &     13.9  \\\\\n",
       "\\bottomrule\n",
       "\\end{tabular}\n",
       "%\\caption{OLS Regression Results}\n",
       "\\end{center}\n",
       "\n",
       "Notes: \\newline\n",
       " [1] Standard Errors assume that the covariance matrix of the errors is correctly specified."
      ],
      "text/plain": [
       "<class 'statsmodels.iolib.summary.Summary'>\n",
       "\"\"\"\n",
       "                            OLS Regression Results                            \n",
       "==============================================================================\n",
       "Dep. Variable:        diversity_ratio   R-squared:                       0.827\n",
       "Model:                            OLS   Adj. R-squared:                  0.822\n",
       "Method:                 Least Squares   F-statistic:                     177.1\n",
       "Date:                Tue, 12 Mar 2024   Prob (F-statistic):           1.12e-15\n",
       "Time:                        22:47:11   Log-Likelihood:                 94.625\n",
       "No. Observations:                  39   AIC:                            -185.3\n",
       "Df Residuals:                      37   BIC:                            -181.9\n",
       "Df Model:                           1                                         \n",
       "Covariance Type:            nonrobust                                         \n",
       "================================================================================\n",
       "                   coef    std err          t      P>|t|      [0.025      0.975]\n",
       "--------------------------------------------------------------------------------\n",
       "const            0.0909      0.024      3.736      0.001       0.042       0.140\n",
       "english_only     0.3754      0.028     13.307      0.000       0.318       0.433\n",
       "==============================================================================\n",
       "Omnibus:                        1.297   Durbin-Watson:                   1.591\n",
       "Prob(Omnibus):                  0.523   Jarque-Bera (JB):                1.044\n",
       "Skew:                          -0.155   Prob(JB):                        0.593\n",
       "Kurtosis:                       2.261   Cond. No.                         13.9\n",
       "==============================================================================\n",
       "\n",
       "Notes:\n",
       "[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.\n",
       "\"\"\""
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X = diverse_lang['english_only']\n",
    "Y = diverse_lang['diversity_ratio']\n",
    "X = sm.add_constant(X)\n",
    "m = sm.OLS(Y.astype(float), X.astype(float))\n",
    "\n",
    "r = m.fit()\n",
    "r.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***\n",
    "## **Impact and Limitations**\n",
    "***\n",
    "&emsp; Our greatest informant and limitation was our reliance on the US Census Bureau for reliable data. As 4 out of 5 of the datasets we chose to analyze were obtained from this singular, albeit grand, source, we believe that it is natural that our analysis would extend the same biases and limitations. As mentioned above in the data setting section, generally, census data is prone to response bias, with social desirability bias arguably the most susceptible to the responders as it deals with demographic data. An implication of this can be that responders of certain cultures and demographics that are less recognized in the United States may not have felt the same inclination for declaring their ancestry and language compared to those who are in communities that are actively celebrated. Especially as we look at ancestry in Washington state, we have to recognize that there are communities that had their lineage systemically erased from archives and history, such as the African and Indigenous Americans, and therefore the responders may not be able to report their full ancestral background. We also noticed the lack of AAPI ancestry in our data. With the dataset’s notes stating that “this table lists only the largest ancestry groups…” and that it only recorded the first and second ancestry, we questioned how the US Census defined “largest” and what groups made that “largest” cutoff. While they also redirected to “more detailed tables” for more ancestral groups, we agreed that this was an example of erasure, as it initially conveyed that there were no people of AAPI ancestry in Washington state. \n",
    "\n",
    "&emsp; As for our graphs, we recognize that there is skewing of the axes for a closer look at the visualizations, which can lead to unintentional misinformed opinions and understandings. While we did not see a correlation between the per pupil expenditures and the languages spoken in each county, we can see that it is apparent that there is a high proportion of Spanish speakers in comparison to the other non-English languages. This is true for the visualizations showing educational attainment by language and, although it is a loose trend, the counties with the most amount of Spanish speaker seemed to have the least amount of educational attainment. We found trends interesting, as we first thought that language spoken did not have any influence in the ways counties are supported and uplifted, however we urge viewers to think critically about other socioeconomic factors that we failed to highlight in our project that are popular indicators of wellbeing (eg. race, income). We also acknowledge that we were only able to analyze one year’s worth of data, which decreases the reliability of our project. If we were able to invest more time into this project, we envision that we would have been able to produce much more reliable and valid results.  \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***\n",
    "## **Challenge Goals**\n",
    "***\n",
    "\n",
    "### **Multiple Datasets:**\n",
    "\n",
    "&emsp; As mentioned in the data setting section, we used multiple datasets from the US Census in order to compare trends across Washington counties by connecting location based data, the Washington county, as our primary key. For example, to answer our third research question, we have taken data about the spoken language diversity of Washington counties and also data about county-specific ancestral backgrounds and have merged them together with the county being the main denominator. By using multiple datasets, we were able to achieve higher relationality and diversity in the kinds of data that were analyzed.\n",
    "### **New Libraries:** \n",
    "\n",
    "&emsp; We have mainly used Plotly Express and Plotly Graph Objects from the Plotly library to create interactive visualizations to support the communication of our analyses. We believe that including visualizations that have some form of interactivity with a viewer encourages more direct attention and interpretation. We especially chose to lean into the hover label feature of Plotly, which allows for the viewer to hover over a data point on a visualization and indicate its x and y values without having to physically reference the axis. We found that because we wanted to communicate relationships between features, stacking the plot on top of one another created a sense of relativity, with the hover labels helping to highlight the more granular information, allowing for data to be conveyed more transparently.\n",
    "\n",
    "### **Messy Data**:\n",
    "\n",
    "&emsp; We initially did not believe that we would have to deal with messy data, as our first glance at our datasets seemed to have been stored neatly. We quickly realized that the data from the robust US Census’s interactive interface did not translate as well when reading them as CSVs for analysis. Multi-indexes and column sections and headings were particularly messy, as we had to manually separate them with regex patterns, pivot the tables, and rename the columns to remove non-breaking and white spaces. As we were also using a dataset that was from collectors outside of the US Census, we had to normalize the county and district names to make sure joins and merges of the separate tables were performed correctly without data loss.\n",
    " \n",
    "### **Result Validity**:\n",
    "\n",
    "&emsp; After looking at the results of our first visualization from our third research question, we deemed that performing a linear regression on the two variables, ancestral diversity and the number of households that spoke English exclusively, could produce a meaningful output. Although not as major as the other challenge goals, we felt that the inclusion of statistical analysis to answer this question helped strengthen our overall understanding of the relationships about language diversity within Washington state. \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***\n",
    "## **Plan Evaluation**\n",
    "***\n",
    "### **Time Utilized:**\n",
    "\n",
    "&emsp; Our proposed work plan time estimates were relatively accurate. Our estimates were close to reality for the most part as we were able judge based on previous experience in working with datasets and visualizations from class assignments in CSE 163. The two areas that took longer than anticipated were cleaning the data and creating the visualizations. Since we initially did not anticipate having to clean the data much, we estimated a lower amount of time spent on this step. However, as mentioned previously, the datasets ended up being quite messy and required a lengthy amount of cleaning code and time. For creating the visualizations, we took longer than expected since we had not gotten much experience using Plotly as it was a new library from the one(s) using during class assignments. Other than these two areas, we were able to follow our proposed plan fairly accurately and spent a fair amount of time on each step of this research project.\n",
    "\n",
    "### **Developing Code:**\n",
    "\n",
    "&emsp; For each high-level section, the work was divided into half. Before each member went off to work independently, conversations were held ahead of time in order to discuss the scope and define what half of the workload would look like. For each research question, instead of directly using pandas and Python to wrangle the data, we seperated chunks of code to establish a basis for testing and validation later on. \n",
    "\n",
    "### **Testing Code:**\n",
    "\n",
    "&emsp; For each research question, as well as the cleaning functions, the member responsible for the majority of the code worked on the corresponding test cases. This allowed for the person most familiar with the code and thought process to curate the test cases for them.\n",
    "\n",
    "### **Coordinating Work:**\n",
    "\n",
    "&emsp; Throughout this project, all members discussed with one another before and after starting each high-level section. All members notified the other member about potential challenges or conflicts as soon as possible, and constant communication was encouraged to make sure no member felt unsupported.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***\n",
    "## **Testing**\n",
    "***\n",
    "&emsp; We tested our code by using a variety of assertations, doctests, and statistical regression evaluations. The majority of testing was done using assert statements. We compared the data values contained in each created graph with the values held in each dataframe corresponding to its respective graph. This helped ensure that no values were lost or added during the graph creation. For the cleaning functions, we used doctests and a smaller testing data file. The doctests can be found within the docstring inside each cleaning function located in the Results and Code section of this report, and the smaller data file can be located in our project repository as 'small_census_test.csv'. We know that our code computes the expected result because our assertation tests include statements to check sorted groupings of values. This not only ensures that all values we want to include in the graph are included, but also guarantees that the values are presented in the correct order or manner. By comparing sorted values, we can make sure that the highest and lowest values are in the right place in relativity to each other. This is increasingly important as many of our visualizations rely on sorted values in order to make conclusions and takeways more clear and concise. Additionally, to check for the goodness of the linear model used in the last research question, we found the mean squared error of the model and found it to be at around 0.2, which is fairly close to 0, meaning that the linear model was a good fit for the data it was being used on. The code for all of our testing (excluding the doctests found in each cleaning function located in the Results and Code section of this report) can be found below. \n",
    "\n",
    "**Assert statements for RQ1 code:**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Undergraduate data\n",
    "assert sorted(fig1.to_dict()[\"data\"][0][\"y\"]) == sorted(\n",
    "    sub_enrollment[\n",
    "        \"college,_undergraduate\"].tolist()), \"Undergrad data does not match expected\"\n",
    "# Postgrad data\n",
    "assert sorted(fig1.to_dict()[\"data\"][1][\"y\"]) == sorted(\n",
    "    sub_enrollment[\n",
    "        \"graduate,_professional_school\"].tolist()), \"Postgrad data does not match expected\"\n",
    "# Spanish data\n",
    "assert sorted(fig1.to_dict()[\"data\"][2][\"y\"]) == sorted(\n",
    "    sub_language[\n",
    "        \"spanish\"].tolist()), \"Spanish data does not match expected\"\n",
    "# Indo-Euro data\n",
    "assert sorted(fig1.to_dict()[\"data\"][5][\"y\"]) == sorted(\n",
    "    sub_language[\n",
    "        \"other_indo-european_languages\"].tolist()), \"Indo-European data does not match expected\"\n",
    "# Asian data\n",
    "assert sorted(fig1.to_dict()[\"data\"][8][\"y\"]) == sorted(\n",
    "    sub_language[\n",
    "        \"asian_and_pacific_island_languages\"].tolist()), \"API data does not match expected\"\n",
    "# Other data\n",
    "assert sorted(fig1.to_dict()[\"data\"][11][\"y\"]) == sorted(\n",
    "    sub_language[\n",
    "        \"other_languages\"].tolist()), \"Other language data does not match expected\"\n",
    "# English data\n",
    "assert sorted(fig1.to_dict()[\"data\"][14][\"y\"]) == sorted(\n",
    "    sub_language[\n",
    "        \"speak_only_english\"].tolist()), \"English data does not match expected\"\n",
    "# Other than English data\n",
    "assert sorted(fig1.to_dict()[\"data\"][17][\"y\"]) == sorted(\n",
    "    sub_language[\n",
    "        \"speak_a_language_other_than_english\"].tolist()), \"Other than English data does not match expected\"\n",
    "# Counties\n",
    "assert sorted(fig1.to_dict()[\"data\"][0][\"x\"]) == sorted(\n",
    "    enrollment.index.get_level_values(\"County\")), \"Counties not accounted for\"\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Assert statements for RQ2 code:**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Testing for all counties included and are sorted by the PPE\n",
    "ppe_languages_sorted = ppe_languages.sort_values(by=\"ppe\", ascending=False).index\n",
    "for i in range(len(fig2.to_dict()[\"data\"])):\n",
    "    all_labels = fig2.to_dict()[\"data\"][i][\"x\"]\n",
    "    for label, idx in zip(all_labels, ppe_languages_sorted):\n",
    "        assert(label.split(\" \", 1)[1] == idx), \"Data does not match expected\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Assert statements and statistical analysis evaluations for RQ3 code:**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Testing for all data points to be on the plot\n",
    "assert sorted(fig3.to_dict()['data'][0]['x']) == sorted(\n",
    "    diverse_lang['english_only'].tolist()), \"Data points do not match expected\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.20066900124783196"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# The mean squared error for checking the goodness of fit of the linear model\n",
    "sm.tools.eval_measures.mse(diverse_lang['english_only'], diverse_lang['diversity_ratio'], axis=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***\n",
    "## **Collaboration**\n",
    "*** \n",
    "&emsp; In the process of this project, we consulted the [Plotly documentation](https://plotly.com/python/) for guidance on using the Plotly library, University of Washington's Professor Ott Toomet's textbooks ([1](https://faculty.washington.edu/otoomet/machinelearning-py/linear-regression.html), [2](https://faculty.washington.edu/otoomet/machineLearning.pdf)) on Python for Machine Learning for linear regression and general statistical analysis and interpretation, and [Stack Overflow](https://stackoverflow.com/) for advice on debugging code. We have not used generative AI in any way for this project."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
